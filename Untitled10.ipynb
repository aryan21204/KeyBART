{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FC-bp34WAYOU",
        "outputId": "c1697955-ed3a-41a8-971b-02f0cdcdd530"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keybert in /usr/local/lib/python3.10/dist-packages (0.8.5)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from keybert) (1.25.2)\n",
            "Requirement already satisfied: rich>=10.4.0 in /usr/local/lib/python3.10/dist-packages (from keybert) (13.7.1)\n",
            "Requirement already satisfied: scikit-learn>=0.22.2 in /usr/local/lib/python3.10/dist-packages (from keybert) (1.2.2)\n",
            "Requirement already satisfied: sentence-transformers>=0.3.8 in /usr/local/lib/python3.10/dist-packages (from keybert) (3.0.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.4.0->keybert) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.4.0->keybert) (2.16.1)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22.2->keybert) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22.2->keybert) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22.2->keybert) (3.5.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.3.8->keybert) (4.41.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.3.8->keybert) (4.66.4)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.3.8->keybert) (2.3.0+cu121)\n",
            "Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.3.8->keybert) (0.23.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.3.8->keybert) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers>=0.3.8->keybert) (3.15.3)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers>=0.3.8->keybert) (2023.6.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers>=0.3.8->keybert) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers>=0.3.8->keybert) (6.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers>=0.3.8->keybert) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers>=0.3.8->keybert) (4.12.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.4.0->keybert) (0.1.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (12.5.40)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers>=0.3.8->keybert) (2024.5.15)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers>=0.3.8->keybert) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers>=0.3.8->keybert) (0.4.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers>=0.3.8->keybert) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers>=0.3.8->keybert) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers>=0.3.8->keybert) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers>=0.3.8->keybert) (2024.6.2)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "pip install keybert"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keybert import KeyBERT\n",
        "\n",
        "# Initialize KeyBERT model\n",
        "kw_model = KeyBERT()\n",
        "\n",
        "# Example strings\n",
        "texts = [\n",
        "    \"The quick brown fox jumps over the lazy dog.\",\n",
        "    \"Artificial intelligence and machine learning are transforming the world.\",\n",
        "    \"Python is a versatile programming language used for web development, data analysis, and more.\",\n",
        "    \"Climate change is one of the most pressing issues of our time.\",\n",
        "    \"The stock market saw a significant increase in the last quarter.\",\n",
        "    \"Advancements in biotechnology are paving the way for new medical treatments.\",\n",
        "    \"The novel coronavirus pandemic has impacted global economies and healthcare systems.\",\n",
        "    \"Renewable energy sources like solar and wind power are becoming more popular.\",\n",
        "    \"The education system is evolving with the integration of technology in classrooms.\",\n",
        "    \"Space exploration missions have provided valuable insights into our universe.\"\n",
        "]\n",
        "\n",
        "\n",
        "for i, text in enumerate(texts):\n",
        "    keywords = kw_model.extract_keywords(text,\n",
        "                                         keyphrase_ngram_range=(1, 2),\n",
        "                                         stop_words='english',\n",
        "                                         highlight=False,\n",
        "                                         top_n=5)\n",
        "    print(f\"Text {i+1}: {text}\")\n",
        "\n",
        "    print(\"Keywords:\", [keyword for keyword, _ in keywords])\n",
        "    print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iRz8LpsvAbnd",
        "outputId": "f741c8cb-08c8-4c92-9d94-06c15060e890"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text 1: The quick brown fox jumps over the lazy dog.\n",
            "Keywords: ['fox jumps', 'brown fox', 'lazy dog', 'jumps lazy', 'fox']\n",
            "\n",
            "Text 2: Artificial intelligence and machine learning are transforming the world.\n",
            "Keywords: ['transforming world', 'artificial intelligence', 'learning transforming', 'intelligence machine', 'machine learning']\n",
            "\n",
            "Text 3: Python is a versatile programming language used for web development, data analysis, and more.\n",
            "Keywords: ['python', 'python versatile', 'programming language', 'programming', 'web development']\n",
            "\n",
            "Text 4: Climate change is one of the most pressing issues of our time.\n",
            "Keywords: ['climate change', 'climate', 'pressing issues', 'change pressing', 'issues']\n",
            "\n",
            "Text 5: The stock market saw a significant increase in the last quarter.\n",
            "Keywords: ['significant increase', 'stock market', 'increase quarter', 'increase', 'stock']\n",
            "\n",
            "Text 6: Advancements in biotechnology are paving the way for new medical treatments.\n",
            "Keywords: ['advancements biotechnology', 'biotechnology', 'biotechnology paving', 'medical treatments', 'new medical']\n",
            "\n",
            "Text 7: The novel coronavirus pandemic has impacted global economies and healthcare systems.\n",
            "Keywords: ['coronavirus pandemic', 'coronavirus', 'novel coronavirus', 'pandemic', 'pandemic impacted']\n",
            "\n",
            "Text 8: Renewable energy sources like solar and wind power are becoming more popular.\n",
            "Keywords: ['renewable energy', 'energy sources', 'renewable', 'solar wind', 'wind power']\n",
            "\n",
            "Text 9: The education system is evolving with the integration of technology in classrooms.\n",
            "Keywords: ['technology classrooms', 'education evolving', 'classrooms', 'integration technology', 'technology']\n",
            "\n",
            "Text 10: Space exploration missions have provided valuable insights into our universe.\n",
            "Keywords: ['exploration missions', 'space exploration', 'exploration', 'missions', 'missions provided']\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from keybert import KeyBERT\n",
        "\n",
        "# Initialize KeyBERT model\n",
        "kw_model = KeyBERT()\n",
        "\n",
        "# Load data from the Excel file\n",
        "file_path = 'tlt.xlsx'\n",
        "df = pd.read_excel(file_path)\n",
        "\n",
        "# Assuming the columns are named 'Title' and 'Purpose_Util_Plan'\n",
        "# Drop rows where either column has NaN or non-string values\n",
        "df = df.dropna(subset=['Title', 'Purpose_Util_Plan'])\n",
        "#df = df[df['Title'].apply(lambda x: isinstance(x, str))]\n",
        "#df = df[df['Purpose_Util_Plan'].apply(lambda x: isinstance(x, str))]\n",
        "\n",
        "# Convert the columns to lists\n",
        "texts_column_1 = df['Title'].tolist()\n",
        "texts_column_2 = df['Purpose_Util_Plan'].tolist()\n",
        "\n",
        "# Ensure both columns have the same number of texts\n",
        "assert len(texts_column_1) == len(texts_column_2), \"Both columns must have the same number of texts\"\n",
        "\n",
        "# Extract keywords\n",
        "for i, (text1, text2) in enumerate(zip(texts_column_1, texts_column_2)):\n",
        "    keywords1 = kw_model.extract_keywords(text1, keyphrase_ngram_range=(1, 1), stop_words='english', top_n=5)\n",
        "    keywords2 = kw_model.extract_keywords(text2, keyphrase_ngram_range=(1, 1), stop_words='english', top_n=5)\n",
        "\n",
        "    print(f\"Text {i+1} Title: {text1}\")\n",
        "    print(\"Keywords:\", [keyword for keyword, _ in keywords1])\n",
        "    print()\n",
        "\n",
        "    print(f\"Text {i+1} Purpose_Util_Plan: {text2}\")\n",
        "    print(\"Keywords:\", [keyword for keyword, _ in keywords2])\n",
        "    print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Db_HtHt0YCuQ",
        "outputId": "43cc55b6-3305-44d8-b2d0-25d51e6d7c76"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text 1 Title: Bixby 1.0 NLG data ranked\n",
            "Keywords: ['bixby', 'nlg', 'ranked', 'data']\n",
            "\n",
            "Text 1 Purpose_Util_Plan: - purpose  For bixby CN Voice part, we receive user VOC complain the TTS in bixby 2.0 is not good as bixby 1.0 . As we (R&D side) need to do some internal investigation to find the root cause, due to the TTS quality is rely on the NLG output, so we need to get the bixby 1.0's NLG raw data (ranked by user's domain frequency) to dig into details. finally, we need the data as below table native app : from 1-20. CP app : from 1-20  rank by use frequency - utilization plan(expected benefit - amount, quantity, volume)\n",
            "Keywords: ['bixby', 'tts', 'nlg', 'cn', 'voice']\n",
            "\n",
            "Text 2 Title: S10 Thanks letter for eDM 7\n",
            "Keywords: ['s10', 'edm', 'letter', 'thanks']\n",
            "\n",
            "Text 2 Purpose_Util_Plan: This is for sending the Thanks letter from DJ Koh to all the S10/S10+/S10e customers for eDM.\n",
            "Keywords: ['s10e', 's10', 'edm', 'letter', 'koh']\n",
            "\n",
            "Text 3 Title: Bixby actual ignition sampling data request\n",
            "Keywords: ['bixby', 'sampling', 'ignition', 'data', 'request']\n",
            "\n",
            "Text 3 Purpose_Util_Plan: - Improvement of usability through analysis of actual Bixby user ignition for request purpose - 100% guarantee of Bixby Top 20 goal operation of utilization plan (expected effect through use of big data - quantity / amount)\n",
            "Keywords: ['bixby', 'utilization', 'usability', 'ignition', 'purpose']\n",
            "\n",
            "Text 4 Title: SEJ December AccountData Req\n",
            "Keywords: ['accountdata', 'sej', 'req', 'december']\n",
            "\n",
            "Text 4 Purpose_Util_Plan: - Improvement of usability through analysis of actual Bixby user ignition for request purpose - 100% guarantee of Bixby Top 20 goal operation of utilization plan (expected effect through use of big data - quantity / amount)\n",
            "Keywords: ['bixby', 'utilization', 'usability', 'ignition', 'purpose']\n",
            "\n",
            "Text 5 Title: Request user statistics by age / gender of Samsung Pay\n",
            "Keywords: ['samsung', 'statistics', 'gender', 'age', 'pay']\n",
            "\n",
            "Text 5 Purpose_Util_Plan: - Purpose of request: Analysis of statistics by age / gender of Samsung Pay users - Utilization plan (expected effect through big data utilization - quantity / amount): Refer to when establishing target marketing strategy\n",
            "Keywords: ['utilization', 'samsung', 'marketing', 'statistics', 'data']\n",
            "\n",
            "Text 6 Title: Global Tablet Usage Survey\n",
            "Keywords: ['tablet', 'global', 'survey', 'usage']\n",
            "\n",
            "Text 6 Purpose_Util_Plan: - Purpose of request: To establish target customer group and USP based on previous work data when establishing new model marketing strategy. - Utilization plan (expected effect through big data utilization - quantity / amount): Establish a 20-year Tablet Portfolio marketing strategy, establish a customer group for each model, and create a use case through analysis of USP establishment main usability accordingly\n",
            "Keywords: ['utilization', 'marketing', 'portfolio', 'usp', 'strategy']\n",
            "\n",
            "Text 7 Title: Information Ranking APPs\n",
            "Keywords: ['ranking', 'apps', 'information']\n",
            "\n",
            "Text 7 Purpose_Util_Plan: - Request: We need to know what is the number of downloads for this models: A10, A20, A30, A50, A70, A80, S10e, S10, S10+, Note10 and Note10+ of the mobiles applications attached in the file by this range of age/gender: Men 18-24 ; Men 25-29, Men 30-34, Men 35-40, Men 41+, Women 18-24, Women 25-29, Women 30-34, Women 35-40, Women 41+. - purpose: to know the most important applications mobiles in each model of serie A and S; for planning    establish commercial alliances with other brands.   - utilization plan(expected benefit - amount, quantity, volume): We only need to analice the information to -\n",
            "Keywords: ['mobiles', 'utilization', 'a10', 'a20', 'note10']\n",
            "\n",
            "Text 8 Title: Google One app usage rate of Metro customers\n",
            "Keywords: ['metro', 'rate', 'customers', 'app', 'google']\n",
            "\n",
            "Text 8 Purpose_Util_Plan: - To review whether the Metro service provider Preload app (Google One) is installed for the purpose of request. - Utilization plan (expected effect through big data utilization - quantity / amount) Increase user experience of about 3.7 million customers who use our terminal in Metro channel. (Based on annual sales volume of Metro terminals equipped with Google One app)\n",
            "Keywords: ['metro', 'preload', 'utilization', 'app', 'provider']\n",
            "\n",
            "Text 9 Title: Identify screen recording usage behavior (rerun usability)\n",
            "Keywords: ['recording', 'screen', 'usability', 'behavior', 'usage']\n",
            "\n",
            "Text 9 Purpose_Util_Plan: - Purpose of request: Find out how many times you use it continuously and refer to it to decide whether to add the 'pause' function or not. - Utilization plan (expected effect through big data utilization - quantity / amount): Review the necessity of the 'pause' function proposed to be added to the 'screen recording' function. (Used as reference data) Ultimately, the screen recording function is advanced to increase the competitiveness of our products.\n",
            "Keywords: ['utilization', 'pause', 'recording', 'screen', 'purpose']\n",
            "\n",
            "Text 10 Title: 2020 Underlying Segments Request\n",
            "Keywords: ['segments', '2020', 'request', 'underlying']\n",
            "\n",
            "Text 10 Purpose_Util_Plan: - Purpose of request: Segmentation progress using information based on Samsung account registration terminal - Utilization plan (expected effect through big data utilization - quantity / amount): Induce product purchase and increase royalties by sending target messages for each segment\n",
            "Keywords: ['segmentation', 'samsung', 'utilization', 'segment', 'registration']\n",
            "\n",
            "Text 11 Title: Microsoft Service Analysis\n",
            "Keywords: ['service', 'microsoft', 'analysis']\n",
            "\n",
            "Text 11 Purpose_Util_Plan: - Purpose of request: Workshop with Microsoft - Increase terminal sales through collaboration of utilization plan (expected effect through big data utilization - quantity / amount)\n",
            "Keywords: ['utilization', 'workshop', 'sales', 'microsoft', 'collaboration']\n",
            "\n",
            "Text 12 Title: Application for sharing data of customers who purchase more than 3 flagship terminals\n",
            "Keywords: ['customers', 'terminals', 'flagship', 'data', 'sharing']\n",
            "\n",
            "Text 12 Purpose_Util_Plan: - Request purpose - Promote W20 S / O\n",
            "Keywords: ['promote', 'w20', 'purpose', 'request']\n",
            "\n",
            "Text 13 Title: Upgrade IM\n",
            "Keywords: ['upgrade', 'im']\n",
            "\n",
            "Text 13 Purpose_Util_Plan: - purpose : analysis on target purchase behaviour - utilization plan(expected benefit - amount, quantity, volume) : statistical analysis\n",
            "Keywords: ['utilization', 'target', 'purchase', 'behaviour', 'quantity']\n",
            "\n",
            "Text 14 Title: Request for extraction of life event targets in January 20\n",
            "Keywords: ['event', 'extraction', 'january', 'life', 'targets']\n",
            "\n",
            "Text 14 Purpose_Util_Plan: Purpose of request 1) 'Request for target list to guide digital plaza purchase benefits in January 20 - Utilization plan 1) Marketing reception agreement / SMS reception agreement / 3rd party provision agreement point-by-point promotion customer filtering (12/27) 2) Monthly promotion target customer additional point (membership point) policy operation (12/30 ~ 31) Sharing the final route list excluded from delivery date D-2 (12/31)\n",
            "Keywords: ['target', 'promotion', 'marketing', 'benefits', 'provision']\n",
            "\n",
            "Text 15 Title: Analyze the usage pattern of Sero target customers and check the size\n",
            "Keywords: ['customers', 'sero', 'size', 'target', 'analyze']\n",
            "\n",
            "Text 15 Purpose_Util_Plan: - Purpose of request: Used for distribution of Sero CDM Guide before global launch (end of March ~) - Utilization plan (expected effect through big data utilization - quantity / amount). Securing target customer profile and marketing appeal points through analysis of The Sero soft launch (Korea) case and mobile flagship customer usage pattern. Distribution of Sero CDM Guide before global launch (The Sero 30,000 units per year challenge)\n",
            "Keywords: ['sero', 'cdm', 'flagship', 'marketing', 'utilization']\n",
            "\n",
            "Text 16 Title: N10 Lite & A-CDM -Runestone\n",
            "Keywords: ['n10', 'runestone', 'cdm', 'lite']\n",
            "\n",
            "Text 16 Purpose_Util_Plan: Background: Runestone data from HQ Big Data is requested for all Samsung a/c customers of India (customization=yes, marketing opt-in=yes). \n",
            "Keywords: ['samsung', 'runestone', 'data', 'marketing', 'india']\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from keybert import KeyBERT\n",
        "\n",
        "kw_model = KeyBERT()\n",
        "\n",
        "\n",
        "file_path = 'tlt.xlsx'\n",
        "df = pd.read_excel(file_path)\n",
        "\n",
        "# data Preprocessing(cleaning):  Remove rows where either 'Title' or 'Purpose_Util_Plan' columns have missing (NaN) values.\n",
        "df = df.dropna(subset=['Title', 'Purpose_Util_Plan'])\n",
        "\n",
        "# Keep only rows where the 'Title' and 'purpose_util_plan' columns contains string values.\n",
        "# df = df[df['Title'].apply(lambda x: isinstance(x, str))]\n",
        "# df = df[df['Purpose_Util_Plan'].apply(lambda x: isinstance(x, str))]\n",
        "\n",
        "\n",
        "texts_column_1 = df['Title'].tolist()\n",
        "texts_column_2 = df['Purpose_Util_Plan'].tolist()\n",
        "\n",
        "#assert len(texts_column_1) == len(texts_column_2), \"Both columns must have the same number of texts\"\n",
        "\n",
        "\n",
        "for i, (text1, text2) in enumerate(zip(texts_column_1, texts_column_2)):\n",
        "    keywords1 = kw_model.extract_keywords(text1, keyphrase_ngram_range=(1, 1), stop_words='english', top_n=5)\n",
        "    keywords2 = kw_model.extract_keywords(text2, keyphrase_ngram_range=(1, 1), stop_words='english', top_n=10)\n",
        "\n",
        "    print(f\"Text {i+1} Title: {text1}\")\n",
        "    print(\"Keywords:\", [keyword for keyword, _ in keywords1])\n",
        "    print()\n",
        "\n",
        "    print(f\"Text {i+1} Purpose_Util_Plan: {text2}\")\n",
        "    print(\"Keywords:\", [keyword for keyword, _ in keywords2])\n",
        "    print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x9CZ83lAZGeB",
        "outputId": "8e17cbe7-a1dc-4906-e7cc-0444484a16aa"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text 1 Title: Bixby 1.0 NLG data ranked\n",
            "Keywords: ['bixby', 'nlg', 'ranked', 'data']\n",
            "\n",
            "Text 1 Purpose_Util_Plan: - purpose  For bixby CN Voice part, we receive user VOC complain the TTS in bixby 2.0 is not good as bixby 1.0 . As we (R&D side) need to do some internal investigation to find the root cause, due to the TTS quality is rely on the NLG output, so we need to get the bixby 1.0's NLG raw data (ranked by user's domain frequency) to dig into details. finally, we need the data as below table native app : from 1-20. CP app : from 1-20  rank by use frequency - utilization plan(expected benefit - amount, quantity, volume)\n",
            "Keywords: ['bixby', 'tts', 'nlg', 'cn', 'voice', 'utilization', 'frequency', 'voc', 'native', 'ranked']\n",
            "\n",
            "Text 2 Title: S10 Thanks letter for eDM 7\n",
            "Keywords: ['s10', 'edm', 'letter', 'thanks']\n",
            "\n",
            "Text 2 Purpose_Util_Plan: This is for sending the Thanks letter from DJ Koh to all the S10/S10+/S10e customers for eDM.\n",
            "Keywords: ['s10e', 's10', 'edm', 'letter', 'koh', 'dj', 'sending', 'customers', 'thanks']\n",
            "\n",
            "Text 3 Title: Bixby actual ignition sampling data request\n",
            "Keywords: ['bixby', 'sampling', 'ignition', 'data', 'request']\n",
            "\n",
            "Text 3 Purpose_Util_Plan: - Improvement of usability through analysis of actual Bixby user ignition for request purpose - 100% guarantee of Bixby Top 20 goal operation of utilization plan (expected effect through use of big data - quantity / amount)\n",
            "Keywords: ['bixby', 'utilization', 'usability', 'ignition', 'purpose', 'use', 'quantity', 'analysis', 'plan', 'improvement']\n",
            "\n",
            "Text 4 Title: SEJ December AccountData Req\n",
            "Keywords: ['accountdata', 'sej', 'req', 'december']\n",
            "\n",
            "Text 4 Purpose_Util_Plan: - Improvement of usability through analysis of actual Bixby user ignition for request purpose - 100% guarantee of Bixby Top 20 goal operation of utilization plan (expected effect through use of big data - quantity / amount)\n",
            "Keywords: ['bixby', 'utilization', 'usability', 'ignition', 'purpose', 'use', 'quantity', 'analysis', 'plan', 'improvement']\n",
            "\n",
            "Text 5 Title: Request user statistics by age / gender of Samsung Pay\n",
            "Keywords: ['samsung', 'statistics', 'gender', 'age', 'pay']\n",
            "\n",
            "Text 5 Purpose_Util_Plan: - Purpose of request: Analysis of statistics by age / gender of Samsung Pay users - Utilization plan (expected effect through big data utilization - quantity / amount): Refer to when establishing target marketing strategy\n",
            "Keywords: ['utilization', 'samsung', 'marketing', 'statistics', 'data', 'analysis', 'gender', 'target', 'users', 'request']\n",
            "\n",
            "Text 6 Title: Global Tablet Usage Survey\n",
            "Keywords: ['tablet', 'global', 'survey', 'usage']\n",
            "\n",
            "Text 6 Purpose_Util_Plan: - Purpose of request: To establish target customer group and USP based on previous work data when establishing new model marketing strategy. - Utilization plan (expected effect through big data utilization - quantity / amount): Establish a 20-year Tablet Portfolio marketing strategy, establish a customer group for each model, and create a use case through analysis of USP establishment main usability accordingly\n",
            "Keywords: ['utilization', 'marketing', 'portfolio', 'usp', 'strategy', 'customer', 'plan', 'establishing', 'usability', 'tablet']\n",
            "\n",
            "Text 7 Title: Information Ranking APPs\n",
            "Keywords: ['ranking', 'apps', 'information']\n",
            "\n",
            "Text 7 Purpose_Util_Plan: - Request: We need to know what is the number of downloads for this models: A10, A20, A30, A50, A70, A80, S10e, S10, S10+, Note10 and Note10+ of the mobiles applications attached in the file by this range of age/gender: Men 18-24 ; Men 25-29, Men 30-34, Men 35-40, Men 41+, Women 18-24, Women 25-29, Women 30-34, Women 35-40, Women 41+. - purpose: to know the most important applications mobiles in each model of serie A and S; for planning    establish commercial alliances with other brands.   - utilization plan(expected benefit - amount, quantity, volume): We only need to analice the information to -\n",
            "Keywords: ['mobiles', 'utilization', 'a10', 'a20', 'note10', 'applications', 'models', 's10e', 's10', 'model']\n",
            "\n",
            "Text 8 Title: Google One app usage rate of Metro customers\n",
            "Keywords: ['metro', 'rate', 'customers', 'app', 'google']\n",
            "\n",
            "Text 8 Purpose_Util_Plan: - To review whether the Metro service provider Preload app (Google One) is installed for the purpose of request. - Utilization plan (expected effect through big data utilization - quantity / amount) Increase user experience of about 3.7 million customers who use our terminal in Metro channel. (Based on annual sales volume of Metro terminals equipped with Google One app)\n",
            "Keywords: ['metro', 'preload', 'utilization', 'app', 'provider', 'service', 'google', 'use', 'plan', 'customers']\n",
            "\n",
            "Text 9 Title: Identify screen recording usage behavior (rerun usability)\n",
            "Keywords: ['recording', 'screen', 'usability', 'behavior', 'usage']\n",
            "\n",
            "Text 9 Purpose_Util_Plan: - Purpose of request: Find out how many times you use it continuously and refer to it to decide whether to add the 'pause' function or not. - Utilization plan (expected effect through big data utilization - quantity / amount): Review the necessity of the 'pause' function proposed to be added to the 'screen recording' function. (Used as reference data) Ultimately, the screen recording function is advanced to increase the competitiveness of our products.\n",
            "Keywords: ['utilization', 'pause', 'recording', 'screen', 'purpose', 'data', 'use', 'continuously', 'function', 'used']\n",
            "\n",
            "Text 10 Title: 2020 Underlying Segments Request\n",
            "Keywords: ['segments', '2020', 'request', 'underlying']\n",
            "\n",
            "Text 10 Purpose_Util_Plan: - Purpose of request: Segmentation progress using information based on Samsung account registration terminal - Utilization plan (expected effect through big data utilization - quantity / amount): Induce product purchase and increase royalties by sending target messages for each segment\n",
            "Keywords: ['segmentation', 'samsung', 'utilization', 'segment', 'registration', 'progress', 'data', 'royalties', 'purchase', 'account']\n",
            "\n",
            "Text 11 Title: Microsoft Service Analysis\n",
            "Keywords: ['service', 'microsoft', 'analysis']\n",
            "\n",
            "Text 11 Purpose_Util_Plan: - Purpose of request: Workshop with Microsoft - Increase terminal sales through collaboration of utilization plan (expected effect through big data utilization - quantity / amount)\n",
            "Keywords: ['utilization', 'workshop', 'sales', 'microsoft', 'collaboration', 'increase', 'terminal', 'data', 'request', 'plan']\n",
            "\n",
            "Text 12 Title: Application for sharing data of customers who purchase more than 3 flagship terminals\n",
            "Keywords: ['customers', 'terminals', 'flagship', 'data', 'sharing']\n",
            "\n",
            "Text 12 Purpose_Util_Plan: - Request purpose - Promote W20 S / O\n",
            "Keywords: ['promote', 'w20', 'purpose', 'request']\n",
            "\n",
            "Text 13 Title: Upgrade IM\n",
            "Keywords: ['upgrade', 'im']\n",
            "\n",
            "Text 13 Purpose_Util_Plan: - purpose : analysis on target purchase behaviour - utilization plan(expected benefit - amount, quantity, volume) : statistical analysis\n",
            "Keywords: ['utilization', 'target', 'purchase', 'behaviour', 'quantity', 'benefit', 'statistical', 'analysis', 'plan', 'purpose']\n",
            "\n",
            "Text 14 Title: Request for extraction of life event targets in January 20\n",
            "Keywords: ['event', 'extraction', 'january', 'life', 'targets']\n",
            "\n",
            "Text 14 Purpose_Util_Plan: Purpose of request 1) 'Request for target list to guide digital plaza purchase benefits in January 20 - Utilization plan 1) Marketing reception agreement / SMS reception agreement / 3rd party provision agreement point-by-point promotion customer filtering (12/27) 2) Monthly promotion target customer additional point (membership point) policy operation (12/30 ~ 31) Sharing the final route list excluded from delivery date D-2 (12/31)\n",
            "Keywords: ['target', 'promotion', 'marketing', 'benefits', 'provision', 'utilization', 'plaza', 'delivery', 'monthly', 'purpose']\n",
            "\n",
            "Text 15 Title: Analyze the usage pattern of Sero target customers and check the size\n",
            "Keywords: ['customers', 'sero', 'size', 'target', 'analyze']\n",
            "\n",
            "Text 15 Purpose_Util_Plan: - Purpose of request: Used for distribution of Sero CDM Guide before global launch (end of March ~) - Utilization plan (expected effect through big data utilization - quantity / amount). Securing target customer profile and marketing appeal points through analysis of The Sero soft launch (Korea) case and mobile flagship customer usage pattern. Distribution of Sero CDM Guide before global launch (The Sero 30,000 units per year challenge)\n",
            "Keywords: ['sero', 'cdm', 'flagship', 'marketing', 'utilization', 'mobile', 'launch', 'global', 'usage', 'purpose']\n",
            "\n",
            "Text 16 Title: N10 Lite & A-CDM -Runestone\n",
            "Keywords: ['n10', 'runestone', 'cdm', 'lite']\n",
            "\n",
            "Text 16 Purpose_Util_Plan: Background: Runestone data from HQ Big Data is requested for all Samsung a/c customers of India (customization=yes, marketing opt-in=yes). \n",
            "Keywords: ['samsung', 'runestone', 'data', 'marketing', 'india', 'customers', 'customization', 'hq', 'opt', 'big']\n",
            "\n"
          ]
        }
      ]
    }
  ]
}